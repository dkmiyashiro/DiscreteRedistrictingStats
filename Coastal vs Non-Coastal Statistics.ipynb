{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark 1 Companion Notebook\n",
    "## Discrete Scores of Coastal vs Non-Coastal Districts\n",
    "This notebook is meant to be a companion to the benchmark 1 analysis in the Mathematics of Redistricting textbook (authored by the Mathematics majoring seniors of Willamette University as a part of the Mathematics Senior Seminar course). Throughout the notebook, we will perform basic two-tailed $t$-tests to see whether or not the mean scores of coastal and non-coastal districts significantly differ.\n",
    "\n",
    "First, it is important to have this file saved in the same location as the two .csv files that were also in the GitHub repository (sourced from https://github.com/mggg/DiscreteCompactness); All of our analysis will be done on information from those tables. \n",
    "\n",
    "We encourage the reader to read through the comments of each cell to understand the code better.\n",
    "\n",
    "## Imports\n",
    "Before we begin analysis, we must import a few packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle imports first!\n",
    "\n",
    "# This will be used to create dataframes and read in .csv files.\n",
    "import pandas as pd\n",
    "\n",
    "# This has many quality of life methods for analysis.\n",
    "import numpy as np\n",
    "\n",
    "# This package contains many functions that will basically perform the tests for us.\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the tables\n",
    "\n",
    "Now we read in the tables so that we may look at the data. To see what the tables look like, one can either open the .csv file, or uncomment line 8 or 9 and run the cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the large tables. Ensure that the tables are saved\n",
    "# in the same location (working directory) as this notebook is!\n",
    "\n",
    "bigTable = pd.read_csv('final_big_table.csv', header = 0)\n",
    "zoomTable = pd.read_csv('final_zoom_table.csv', header = 0)\n",
    "\n",
    "# Uncomment these to see what they look like!\n",
    "#bigTable\n",
    "#zoomTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining coastal districts\n",
    "\n",
    "As mentioned in the textbook, there is no variable or delimiters that separate the coastal districts from the non-coastal districts (as far as we could find). As such we manually look at publically available maps and create lists that denote which districts are coastal (along the ocean).\n",
    "\n",
    "While the example in the textbook focuses on the example of California, we have created lists for some other states and their coastal districts. Note, however, that these lists only consider ocean-incident districts, and not those bounded by lakes, mountain ranges, or other natural boundaries that may also cause coastline effects.\n",
    "\n",
    "The districts are denoted by their Geo-ID, as covered in the textbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of coastal districts in ocean-incident states\n",
    "\n",
    "# If you wish to add more states manually, use the following\n",
    "# template:\n",
    "\n",
    "# state = ['State Abbreviation', [CoastalDistrict1, CoastalDistrict2,...]]\n",
    "\n",
    "california = ['CA',[602,603,605,609,611,612,613,614,617,618,620,624,\n",
    "                  626,633,644,647,648,649,651,652,653]]\n",
    "\n",
    "florida = ['FL',[1201,1202,1204,1206,1208,1211,1212,1213,1216,1217,\n",
    "                 1218,1219,1221,1222,1223,1226,1227]]\n",
    "\n",
    "louisiana = ['LA',[2202,2203,2207]]\n",
    "\n",
    "oregon = ['OR', [4101,4103,4104,4105]]\n",
    "\n",
    "texas = ['TX',[4827,4814,4822,4809]]\n",
    "\n",
    "washington = ['WA', [5301,5302,5303,5306]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definition\n",
    "\n",
    "Here we define all of our functions so that we may use them modularly in future cells. The comments in the code go over what each specific function does.\n",
    "\n",
    "Recall that the Welch $t$-test is a parametric test (i.e. requires the source distributions to be normal). As such, we use the Shapiro-Wilk test to test for normality before the Welch $t$-test. \n",
    "\n",
    "If the Shapiro-Wilk test indicates that the data is not a part of a normal distribution, we use the rank transformation on the data before performing the Welch $t$-test.\n",
    "\n",
    "Special Note: Although numpy and scipy/stats do majority of the work, the degrees of freedom must be found manually. Code for this was sourced from https://pythonfordatascience.org/welch-t-test-python-pandas/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method performs the rank transformation that we need\n",
    "# when we \"fail\" the Shapiro-Wilk test.\n",
    "# Note that we wont use this function directly--only through other methods\n",
    "def createRank(array1,array2):\n",
    "    rankingArea = []\n",
    "    rankedArray1 = []\n",
    "    rankedArray2 = []\n",
    "    for x in range(0,len(array1)):\n",
    "        rankingArea.append(array1[x])\n",
    "    for y in range(0,len(array2)):\n",
    "        rankingArea.append(array2[y])\n",
    "    rankingArea.sort()\n",
    "    for z in range(0,len(rankingArea)):\n",
    "        if(rankingArea[z] in array1):\n",
    "            rankedArray1.append(z+1)\n",
    "        else:\n",
    "            rankedArray2.append(z+1)\n",
    "    print('Creating rankings...')\n",
    "    return [rankedArray1, rankedArray2]\n",
    "    \n",
    "    \n",
    "# Python has all the methods built in for the two tailed\n",
    "# t-test. Yay! Assumptions include:\n",
    "    # Normally distributed\n",
    "    # Categorical independent variable\n",
    "    # Numeric dependent variable\n",
    "# Note that we wont use this function directly--only through other methods.\n",
    "def welch_ttest(x, y): \n",
    "    ## Welch-Satterthwaite Degrees of Freedom ##\n",
    "    dof = (np.var(x)/len(x) + np.var(y)/len(y))**2 / ((np.var(x)/len(x))**2 / (len(x)-1) + (np.var(y)/len(y))**2 / (len(y)-1))\n",
    "   \n",
    "    t, p = stats.ttest_ind(x, y, equal_var = False)\n",
    "    \n",
    "    print(\"\\n\",\n",
    "          f\"Welch's t-test= {t:.4f}\", \"\\n\",\n",
    "          f\"p-value = {p:.4f}\", \"\\n\",\n",
    "          f\"Welch-Satterthwaite Degrees of Freedom= {dof:.4f}\")\n",
    "    \n",
    "# Python also has the function that performs the Shapiro-Wilk \n",
    "# test! Basically tests if your sample comes from a normal\n",
    "# distribution.\n",
    "def testNormality(array1, array2):\n",
    "    arrTest1 = stats.shapiro(array1)\n",
    "    arrTest2 = stats.shapiro(array2)\n",
    "    if(arrTest1[1]<0.05 or arrTest2[1]<0.05):\n",
    "        print('May violate normal distribution assumption, or too small sample size!')\n",
    "        if(arrTest1[1]<0.05):\n",
    "            print(arrTest1)\n",
    "            print('The values of the non-coastal districts are to blame!')\n",
    "        if(arrTest2[1]<0.05):\n",
    "            print(arrTest2)\n",
    "            print('The values of the coastal districts are to blame!')\n",
    "\n",
    "# The main code that we'll be using a lot of. It uses\n",
    "# all of the methods above to perform the Welch t-test\n",
    "# on a set of coastal/non-coastal districts. The states\n",
    "# must be defined as they are in the cell before this one.\n",
    "def welchtTest(state, ppType, ranked):\n",
    "    selectedType = 5\n",
    "    \n",
    "    # The 'ppType' parameter chooses what data it will use.\n",
    "    # 0 for weighted, 1 for unweighted\n",
    "    if(ppType ==0 ):\n",
    "        selectedType = 19\n",
    "        print('Discrete Weighted Score Selected!')\n",
    "    elif(ppType ==1):\n",
    "        selectedType = 25\n",
    "        print('Discrete Unweighted Score Selected!')\n",
    "    else:\n",
    "        selectedType = 25\n",
    "        print('Discrete Unweighted Score Selected!')\n",
    "        \n",
    "    # Creates a smaller table/dataframe with just the data\n",
    "    # concerning the inputted state.\n",
    "    stateTable = bigTable[bigTable['state']==state[0]]\n",
    "    coastalList = []\n",
    "    nonCoastalList = []\n",
    "    counter = stateTable.shape[0]\n",
    "    \n",
    "    # Creates two lists based on the defined coastal district\n",
    "    # and the selected data type\n",
    "    for x in range(0,counter):\n",
    "        if(stateTable.iloc[x,1] in state[1]):\n",
    "            coastalList.append(stateTable.iloc[x,selectedType])\n",
    "        else:\n",
    "            nonCoastalList.append(stateTable.iloc[x,selectedType])\n",
    "    \n",
    "    # Makes sure that the numbers are floating points so that \n",
    "    # we can do math with them!\n",
    "    nclFloat = [float(j) for j in nonCoastalList]\n",
    "    clFloat = [float(i) for i in coastalList]\n",
    "    \n",
    "    # The 'ranked' parameter lets you use the rank transformation\n",
    "    # on the data before performing the Welch t-test.\n",
    "    if (ranked):\n",
    "        rankedArrays = createRank(nclFloat,clFloat)\n",
    "        testNormality(rankedArrays[0],rankedArrays[1])\n",
    "        welch_ttest(rankedArrays[0],rankedArrays[1])\n",
    "    else:\n",
    "        testNormality(nclFloat,clFloat)\n",
    "        welch_ttest(nclFloat,clFloat)\n",
    "    print(\"\")\n",
    "\n",
    "# This does nearly the same thing as the above\n",
    "# code, but uses the other large table to compare\n",
    "# continuous Poslby-Popper scores\n",
    "def welchtTestZoom(state, ppType, ranked):\n",
    "    selectedType = 5\n",
    "    if(ppType ==0 ):\n",
    "        selectedType = 7\n",
    "        print('TIGER/Line Score Selected!')\n",
    "    elif(ppType ==1):\n",
    "        selectedType = 8\n",
    "        print('1:500,000 Score Selected!')\n",
    "    elif(ppType==2):\n",
    "        selectedType = 9\n",
    "        print('1:5,000,000 Score Selected!')\n",
    "    else:\n",
    "        selectedType = 10\n",
    "        print('1:20,000,000 Score Selected!')\n",
    "        \n",
    "    stateTable = zoomTable[zoomTable['state']==state[0]]\n",
    "    coastalList = []\n",
    "    nonCoastalList = []\n",
    "    counter = stateTable.shape[0]\n",
    "    for x in range(0,counter):\n",
    "        if(float(stateTable.iloc[x,1]) in state[1]):\n",
    "            coastalList.append(stateTable.iloc[x,selectedType])\n",
    "        else:\n",
    "            nonCoastalList.append(stateTable.iloc[x,selectedType])\n",
    "    nclFloat = [float(j) for j in nonCoastalList]\n",
    "    clFloat = [float(i) for i in coastalList]\n",
    "    if (ranked):\n",
    "        rankedArrays = createRank(nclFloat,clFloat)\n",
    "        testNormality(rankedArrays[0],rankedArrays[1])\n",
    "        welch_ttest(rankedArrays[0],rankedArrays[1])\n",
    "    else:\n",
    "        testNormality(nclFloat,clFloat)\n",
    "        welch_ttest(nclFloat,clFloat)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing analysis (on California)\n",
    "\n",
    "Now we can finally use these functions to analyze the data. The parameters of the welchtTest and welchtTestZoom functions denote what census unit we use to create the dual-graph, or what type of map we want to analyze respectively.\n",
    "\n",
    "From here, we walk through the example given in the textbook by performing the tests on the continuous scores, and then on the discrete scores.\n",
    "\n",
    "### Tests for continuous scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIGER/Line Score Selected!\n",
      "\n",
      " Welch's t-test= 0.2621 \n",
      " p-value = 0.7945 \n",
      " Welch-Satterthwaite Degrees of Freedom= 42.2170\n",
      "\n",
      "1:500,000 Score Selected!\n",
      "\n",
      " Welch's t-test= 1.9053 \n",
      " p-value = 0.0630 \n",
      " Welch-Satterthwaite Degrees of Freedom= 45.9869\n",
      "\n",
      "1:5,000,000 Score Selected!\n",
      "\n",
      " Welch's t-test= 1.6570 \n",
      " p-value = 0.1048 \n",
      " Welch-Satterthwaite Degrees of Freedom= 43.0175\n",
      "\n",
      "1:20,000,000 Score Selected!\n",
      "\n",
      " Welch's t-test= 2.2568 \n",
      " p-value = 0.0292 \n",
      " Welch-Satterthwaite Degrees of Freedom= 43.1056\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tigerLine = welchtTestZoom(california, 0, False)\n",
    "fiveHundredK = welchtTestZoom(california, 1, False)\n",
    "fiveM = welchtTestZoom(california, 2, False)\n",
    "twentyM = welchtTestZoom(california, 3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are no warnings concerning the Shapiro-Wilk test for normality, so we don't need to run the continuous scores through the rank transform. The data above is also in textbook as a table.\n",
    "\n",
    "### Tests for discrete scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete Weighted Score Selected!\n",
      "May violate normal distribution assumption, or too small sample size!\n",
      "(0.5803228616714478, 2.1440062170086094e-08)\n",
      "The values of the non-coastal districts are to blame!\n",
      "(0.5573885440826416, 7.203976792879985e-07)\n",
      "The values of the coastal districts are to blame!\n",
      "\n",
      " Welch's t-test= -1.3322 \n",
      " p-value = 0.1949 \n",
      " Welch-Satterthwaite Degrees of Freedom= 24.9196\n",
      "\n",
      "Discrete Unweighted Score Selected!\n",
      "May violate normal distribution assumption, or too small sample size!\n",
      "(0.7946770191192627, 3.242444290663116e-05)\n",
      "The values of the non-coastal districts are to blame!\n",
      "(0.7693633437156677, 0.00023136104573495686)\n",
      "The values of the coastal districts are to blame!\n",
      "\n",
      " Welch's t-test= -2.1229 \n",
      " p-value = 0.0438 \n",
      " Welch-Satterthwaite Degrees of Freedom= 25.1432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weighted = welchtTest(california, 0, False)\n",
    "unweighted = welchtTest(california, 1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the textbook, we see that the $p$-values for the Shapiro-Wilk test indicate that the scores do not have an underlying normal distribution. As such, we perform the tests again, this time including the rank transform before performing the Welch $t$-test.\n",
    "\n",
    "### Tests for discrete scores with rank transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete Weighted Score Selected!\n",
      "Creating rankings...\n",
      "\n",
      " Welch's t-test= -1.2831 \n",
      " p-value = 0.2067 \n",
      " Welch-Satterthwaite Degrees of Freedom= 41.3223\n",
      "\n",
      "Discrete Unweighted Score Selected!\n",
      "Creating rankings...\n",
      "\n",
      " Welch's t-test= -2.3142 \n",
      " p-value = 0.0256 \n",
      " Welch-Satterthwaite Degrees of Freedom= 42.2055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weightedRanked = welchtTest(california, 0, True)\n",
    "unweightedRanked = welchtTest(california, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, the Welch $t$-test returns negative values for both the weighted and unweighted scores, with a significant $p$-value for the unweighted scores.\n",
    "\n",
    "## Conclusion and Future Testing\n",
    "\n",
    "This notebook was created to assist with simple exploratory data analysis concerning potential discrete analogs of coastal effects. One may use the following empty cells to perform their own tests with the other predefined states to continue the EDA. More comprehensive tests with more manual categorization of districts based on natural boundaries should be done to assure that the analog effect exists and to find the underlying reasons for them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
